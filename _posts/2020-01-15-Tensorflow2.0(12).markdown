---
layout: post
title:  "FGSM"
date:   2020-01-20 09:00:20 +0700
categories: [Tnesorflow2.0]
---
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
### Explaining and Harnessing Adversarial Examples
Code ì°¸ì¡°: <a href="https://www.tensorflow.org/tutorials/generative/adversarial_fgsm?hl=ko">Adversarial example using FGSM</a><br>
ë…¼ë¬¸ ì°¸ì¡°: <a href="https://arxiv.org/pdf/1412.6572.pdf">EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES</a><br>

í•´ë‹¹ Postì˜ ì œëª©ì—ì„œë„ ì•Œ ìˆ˜ ìˆë“¯ì´ Adversarial Examplesì— ëŒ€í•˜ì—¬ í™œìš©í•˜ëŠ”ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ëŠ” Paperì™€ Codeì´ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ ë¨¼ì € Adversarial Exampleì´ë€ ë¬´ì—‡ì¸ì§€ ì‚¬ì „ì§€ì‹ìœ¼ë¡œ ì•Œ ê³  ìˆì–´ì•¼ í•œë‹¤.  

#### (1) Adversarial Example
Adversarial Exampleì— ëŒ€í•´ì„œ ë¨¼ì € ì‚¬ì§„ìœ¼ë¡œ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/Tensorflow/45.png" height="100%" width="100%" /></div><br>
ê¸°ë³¸ì ìœ¼ë¡œ Trainingëœ Modelì€ 57.7%ì˜ Pandaë¼ê³  Classifyë¥¼ í•˜ë‚˜ 8.2%ì˜ nematodeë¼ê³  íŒë‹¨ë˜ëŠ” Noiseë¥¼ í•©ì¹¨ìœ¼ë¡œ ì¸í•˜ì—¬ gibbonì´ë¼ê³  99.3% íŒë‹¨í•˜ê²Œ ëœë‹¤.  

ì¦‰, **Adversarial Exampleì€ Original Image + Pertubation(ë§¤ìš° ì‘ì€ Noise) -> Modelì˜ ì˜¤ë¶„ë¥˜**ë¥¼ ì¼ìœ¼í‚¤ëŠ” Exampleì´ë‹¤.  


#### (2) INTRODUCTION
> ...  
The cause of these adversarial examples was a mystery, and speculative explanations have suggested it is due to extreme nonlinearity of deep neural networks, perhaps combined with insufficient model averaging and insufficient regularization of the purely supervised learning problem.  
We show that these speculative hypotheses are unnecessary. 
Linear behavior in high-dimensional spaces is sufficient to cause adversarial examples.  
This view enables us to design a fast method of generating adversarial examples that makes adversarial training practical.  
...
>

í•´ë‹¹ ë…¼ë¬¸ì˜ Introductionì—ì„œ ê°œì¸ì ìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ë¬¸ì œì´ë‹¤.  
**í˜„ì¬ ë§ì€ Modelì—ì„œëŠ” Adversarial Exampleì— ëŒ€í•œ ëŒ€ì±…ì´ ì¡´ì¬í•˜ì§€ ì•Šë‹¤.**  
ë§ì€ ì´ë“¤ì€ ì´ëŸ¬í•œ ë¬¸ì œì˜ ì›ì¸ì„ í¬ê²Œ 2ê°€ì§€ë¡œ ì„¤ëª…í•˜ê³  ìˆë‹¤.
1. extreme nonlinearity of deep neural networks: DNNì˜ ê·¹ì‹¬í•œ ë¹„ì„ í˜•ì„± ë•Œë¬¸ì´ë‹¤.
2. combined with insufficient model averaging and insufficient regularization of the purely supervised learning problem: ë¶ˆì¶©ë¶„í•œ Modelì˜ ì •ê·œí™” ë•Œë¬¸ì´ë‹¤.

í•˜ì§€ë§Œ í•´ë‹¹ë…¼ë¬¸ì—ì„œëŠ” 1ì´ ë¬¸ì œê°€ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ Linearí•œ Modelì˜ ê³ ì°¨ì›ì—ì„œ ê°™ì€ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ Adversarial Exampleì€ 2ë²ˆì— Focusë¥¼ ë§ì¶”ê³  í•´ê²°í•˜ë©° ëœë‹¤ê³  ì£¼ì¥í•˜ê³  ìˆë‹¤.  
2ë²ˆì˜ ì •ê·œí™”ì˜ ë¬¸ì œëŠ” ì´ì „ê¹Œì§€ëŠ” Dropoutìœ¼ë¡œì„œ í•´ê²°í•˜ë ¤ í•˜ì˜€ìœ¼ë‚˜, í˜„ì¬ ë…¼ë¬¸ì—ì„œëŠ” ì´ê²ƒë³´ë‹¤ ì¢‹ì€ ë°©ë²•ì„ ì œì‹œí•˜ì—¬ Adversarial Exampleì„ í•´ê²°í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆë‹¤.

#### (3) THE LINEAR EXPLANATION OF ADVERSARIAL EXAMPLES
í•´ë‹¹ ë…¼ë¬¸ì€ ìœ„ì—ì„œ Adversarial Exampleì˜ ë¬¸ì œê°€ DNNì˜ ë¹„ì„ í˜•ì„±ì´ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ ê³ ì°¨ì›ì˜ ì„ í˜•ì„±ì—ì„œë„ ì´ëŸ¬í•œ ë¬¸ì œê°€ ë°œìƒí•¨ìœ¼ë¡œì¨ ë³´ì¸ë‹¤ê³  í•˜ì˜€ë‹¤.  
ì´ëŸ¬í•œ ë¬¸ì œëŠ” ê°„ë‹¨í•˜ê²Œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.  
ë¨¼ì € Adversarial Exampleì€ Original Image + Pertubationë¼ê³  í‘œí˜„í•˜ì˜€ê³  ê°ê°ì„ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚´ì–´ ë³´ì.
- Adversarial Example: <span>$$\bar{x}$$</span>
- Original Image: <span>$$x$$</span>
- Pertubation: <span>$$\eta$$</span>

<p>$$\bar{x} = x + \eta$$</p>
ìœ„ì™€ ê°™ì€ ì‹ì„ Linearí•œ Modelì— ë„£ê²Œ ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë³€í˜•ëœë‹¤.  
<p>$$w^{T}\bar{x} = w^{T}x + w^{T}\eta$$</p>
**Adversarial Exampleì€ ìœ„ì˜ ì‹ì—ì„œ Pertubationì— í•´ë‹¹í•˜ëŠ” <span>$$w^{T}\eta$$</span>ì˜ ê°’ì´ ë§¤ìš° ì»¤ì ¸ì„œ Modelì´ ì˜ëª»ëœ Predictionì„ í•œë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.**  
ë”°ë¼ì„œ <span>$$w^{T}\eta$$</span>ì´ ìµœëŒ€ë¡œ ë§Œë“¤ê¸° ìœ„í•˜ì—¬ max norm constraintë¥¼ ì ìš©í•œë‹¤(Linearí•œ Modelì€ High Dimensionì´ë¼ëŠ” ê°€ì •ì´ ìˆê¸° ë•Œë¬¸ì— L1 norm, L2 normì´ ì•„ë‹Œ max norm constraintë¥¼ ì ìš©í•œë‹¤).  
<p>$$||x||_{\infty} = max_{1 \le i \le n}|x_i|$$</p>
ìœ„ì˜ ì‹ì— ì ìš©í•œë‹¤ë©´ <span>$$\eta = \epsilon sign(w)$$</span>ì¼ ë•Œ <span>$$w^{T}\eta$$</span>ì˜ ê°’ì€ ë§¤ìš° ì»¤ì§ˆ ê²ƒ ì´ë‹¤.  

<p>$$\therefore w^{T}\eta = w^{T} \epsilon sign(w) = \epsilon||w||$$</p>
ìœ„ì˜ wì˜ ì ˆëŒ€ê°’ì˜ í‰ê· ì„ mì´ë¼ê³  í•œë‹¤ë©´ ìµœì¢…ì ì¸ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  
<p>$$w^{T}\eta = \epsilon m n\text{(nì€ wì˜ Dimension)}$$</p>
ìœ„ì˜ ì‹ì—ì„œ <span>$$\epsilon$$</span>ì´ ë§¤ìš° ì‘ì€ìˆ˜ë¼ê³  í•˜ì—¬ë„ High Dimensionì˜ ê²½ìš° nê°’ì´ ì»¤ì§ìœ¼ë¡œ ì¸í•˜ì—¬ <span>$$w^{T}\eta$$</span>ì˜ ê°’ì€ ë§¤ìš° ì»¤ì§ˆ ê²ƒì´ë‹¤.  

**ìµœì¢…ì ìœ¼ë¡œ ì •ë¦¬í•˜ê²Œ ë˜ë©´, Noiseì˜ ê°’ì´ ì‘ì€ ê°’ì´ì—¬ë„ High Dimension Linear Modelì—ì„œëŠ” Adversarial Exampleì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.**  

**ì°¸ê³ ì‚¬í•­ (Nromì˜ ì¢…ë¥˜)**  
<p>$$\text{(In all definitions below, )} x = (x_1, x_2, ..., x_n))$$</p>
1. The L1 norm: <span>$$||x||_1 = \sum_{i=1}^{n}|x_i|$$</span>
2. The L2 norm: <span>$$||x||_2 = \sqrt{\sum_{i=1}^{n}x_i^2}$$</span>
3. The infinity norm(or max-norm): <span>$$||x||_{\infty} = max_{1 \le i \le n} |x_i|$$</span>
4. (Less common) Lp norm: <span>$$||x||_p = (\sum_{i=1}^{n}|x_i|^p)^{\frac{1}{p}}$$</span>

#### (4) LINEAR PERTURBATION OF NON-LINEAR MODELS
ì˜ˆì¸¡í•˜ê¸° í˜ë“  ë¬¸ì œ í˜¹ì€ Linearí•œ ìƒíƒœë¡œëŠ” í•´ê²°í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œ(ex) XOR ë¬¸ì œ)ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ ìš°ë¦¬ëŠ” **ë¹„ì„ í˜•ì¸ Activation Functionì„ ì‚¬ìš©í•˜ì—¬ DNN Modelì„ ì‚¬ìš©í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ, í•´ë‹¹ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ DNNì˜ Modelì€ Linearí•œ íŠ¹ì„±ì´ ë§ë‹¤ê³  ì–˜ê¸°í•˜ê³  ìˆê³ , ì´ëŸ¬í•œ ê²°ê³¼ë¡œ ì¸í•˜ì—¬ Adversarial Examplesì— ì·¨ì•½í•˜ë‹¤ê³  ì´ì•¼ê¸° í•œë‹¤.  
ë˜í•œ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ DNNì´ Linearí•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì„ Linear Adversarial Exampleì„ ë§Œë“¤ì–´ì„œ ë³´ì—¬ì£¼ì—ˆìœ¼ë©° ì´ëŸ¬í•œ Linear Adversarial Exampleì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì´ ì´ë²ˆ postì˜ ì œëª©ê³¼ë„ ê°™ì€ FGSM(Fast Gradient Sign Method)ì´ë‹¤.**  
FGSMì˜ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  
- <span>$$x$$</span>: input
- <span>$$y$$</span>: target
- <span>$$\theta$$</span>: hyper parameter
- <span>$$J(\theta,x,y)$$</span>: cost function
- <span>$$\epsilon$$</span>: Noiseì˜ í¬ê¸°(ì‚¬ìš©ìê°€ ì§€ì •, ë§¤ìš° ì‘ì€ ê°’)

<p>$$\eta = \epsilon sign(\triangledown_x J(\theta,x,y))$$</p>
ìœ„ì™€ ê°™ì€ ì‹ìœ¼ë¡œì„œ FGSMì„ ìƒì„±í•˜ê³  <span>$$\bar{x} = x + \eta$$</span>ë¡œì„œ Adversarial Exampleì´ ìƒì„±ëœë‹¤ê³  ì–˜ê¸°í•˜ê³  ìˆë‹¤.  



#### (5) ADVERSARIAL TRAINING OF LINEAR MODELS VERSUS WEIGHT DECAY
ìœ„ì—ì„œ FGSMì„ ì‹¤ì œ Modelì— ë„£ì—ˆì„ ê²½ìš°ë¥¼ ì˜ˆë¥¼ë“¤ì–´ë³´ì.  
í˜„ì¬ ë…¼ë¬¸ì—ì„œ ì˜ˆì‹œë¡œ ë“¤ê³ ìˆëŠ” ì¡°ê±´ê³¼ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  
- <span>Model</span>: Logistic Regression
- <span>Cost Function</span>: Cross Entropy
- <span>Activation Function$\sigma(x)$$</span>: Sigmoid
- <span>$$y \in {-1,1}$$</span>: Label

ë‹¤ìŒê³¼ ê°™ì´ ì¡°ê±´ì´ ì£¼ì–´ì§ˆ ê²½ìš°, <span>$$P(y=1) = \sigma(w^{T}x+b)$$</span>ê°€ ë  ê²ƒì´ê³  **Training Consists of Gradient DescentëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‹ì´ ë  ê²ƒì´ë‹¤.**  
<p>$$\mathbb{E}_{x,y \text{~} p_{data}} \zeta(-y(w^{T}x + b))$$</p>
<p>$$\zeta(z) = log(1+exp(z))$$</p>
ë¨¼ì € ìœ„ì™€ ê°™ì€ ì‹ì´ ì–´ë–»ê²Œ ë‚˜ì™”ëŠ”ì§€ ìƒê°í•´ë³´ì.  
Activation Sigmoid Functionì„ í†µí•˜ì—¬ Cross Entropyì˜ ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  
<p>$$-zlog(\sigma(x))-(1-z)log(1-\sigma(x))$$</p>
ìœ„ì˜ ì‹ì„ ë³€í˜•í•˜ì—¬ ë…¼ë¬¸ê³¼ ê°™ì€ ì‹ì„ ì–»ê³ ì í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.  
<p>$$-zlog(\sigma(x))-(1-z)log(1-\sigma(x))$$</p>
<p>$$= -zlog(\frac{1}{1+e^{-x}})-(1-z)log(\frac{e^{-x}}{1+e^{-x}})$$</p>
<p>$$= zlog(1+e^{-x})+(1-z)(log(1+e^{-x})-log(e^{-x}))$$</p>
<p>$$= zlog(1+e^{-x})+(1-z)(log(1+e^{-x})+x)$$</p>
<p>$$= x - xz + log(1+e^{-x})$$</p>
ìœ„ì˜ ì‹ì—ì„œ <span>$$log(1+e^{-x})$$</span>ì˜ ê·¸ë˜í”„ë¥¼ ì‚´í´ë³´ê²Œ ë˜ë©´ Overflowê°€ ë°œìƒí•  ìœ„í—˜ì´ ë†’ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.  
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/Tensorflow/46.png" height="50%" width="50%" /></div><br>
<p>$$= x-xz + log(1+e^{-x}) = log(e^x)-xz+log(1+e^{-x}) = -xz + log(1+e^{x})$$</p>
ìµœì¢…ì ì¸ ìœ„ì˜ ì‹ì—ì„œ ì¡°ê±´ì¸ <span>$$y \in {-1,1}$$</span>ì„ ê°ê° ëŒ€ì…í•˜ë©´ ìµœì¢…ì ì¸ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  

ìœ„ì˜ ì‹ <span>$$-xz + log(1+e^{x})$$</span>ì— <span>$$z=1$$</span>ì„ ëŒ€ì…í•˜ë©´ ìµœì¢…ì ì¸ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  

**if <span>$$y=1 \rightarrow z(\sigma(w^{T}x+b)) = 1$$</span>**    
<p>$$-xz + log(1+e^{x}) = -x + log(1+e^{x}) = log(1+e^{-x}) = log(1+e^{-yx})$$</p>
**if <span>$$y=-1 \rightarrow z(\sigma(w^{T}x+b)) = 0$$</span>**    
<p>$$-xz + log(1+e^{x}) = log(1+e^{x}) = log(1+e^{-yx})$$</p>
ë”°ë¼ì„œ ìµœì¢…ì ì¸ ì‹ì€ <span>$$x = w^{T}x+b$$</span>ì„ ëŒ€ì…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.  
<p>$$\therefore log(1+e^{-y(w^{T}x+b)})$$</p>
<br>

ì´ì œ ìœ„ì—ì„œ êµ¬í•œ ì‹ìœ¼ë¡œ ì¸í•˜ì—¬ Adversarial Exampleì„ ë§Œë“œëŠ” ê³¼ì •ì„ ìœ ë„í•˜ë„ë¡ í•˜ì.  
ìœ„ì—ì„œ Adversarial Exampleì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•˜ì˜€ë‹¤.  
<p>$$\bar{x} = x + \eta$$</p>
<p>$$\eta = \epsilon sign(\triangledown_x J(\theta,x,y))$$</p>
ìœ„ì˜ ë‘ ì‹ì„ í™œìš©í•˜ê¸° ìœ„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹ì´ ìœ ë„ë  ìˆ˜ ìˆë‹¤.  

**(1) <span>$$\eta = -\epsilon sign(w)$$</span>**  

<p>$$\eta = \epsilon sign(\triangledown_x J(\theta,x,y))$$</p>
<p>$$ = \epsilon sign(\triangledown_x \zeta(-y(w^{T}x + b))$$</p>
ìœ„ì˜ ì‹ì—ì„œ <span>$$f(x) = g(h(x)) \rightarrow f(x)^{'} = h(x)^{'}g(h)^{'}$$</span>ë¥¼ í™œìš©í•˜ë©° ë‹¤ìŒê³¼ ê°™ì€ ì‹ì´ ì„±ë¦½í•œë‹¤.  
<p>$$\triangledown_x \zeta(-y(w^{T}x + b) = -yw*e^{-y(w^{T}x+b)}*\frac{1}{1+e^{-y(w^{T}x+b)}}$$</p>
ìœ„ì˜ ì‹ì—ì„œ <span>$$\frac{1}{1+e^{-y(w^{T}x+b)}}$$</span>ëŠ” Sigmoidì˜ ì‹ì´ë¯€ë¡œ í•­ìƒ ì–‘ìˆ˜, <span>$$e^{-y(w^{T}x+b)}$$</span>ëŠ” ì§€ìˆ˜í•¨ìˆ˜ë¡œì„œ í•­ìƒ ì–‘ìˆ˜ ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  
yì˜ ê°’ì„ ë‹¤ì‹œí•œë²ˆ í™•ì¸í•˜ê³  ì ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.  

**if <span>$$y=1 \rightarrow \frac{1}{1+e^{-y(w^{T}x+b)}} = 1$$</span>**    
<p>$$\eta = \epsilon sign(\triangledown_x J(\theta,x,y)) = -\epsilon sign(w)$$</p>
**if <span>$$y=-1 \rightarrow \frac{1}{1+e^{-y(w^{T}x+b)}} = 0$$</span>**    
<p>$$\eta = \epsilon sign(\triangledown_x J(\theta,x,y)) = 0$$</p>
<p>$$\therefore \eta = -\epsilon sign(w)$$</p>
**(2) <span>$$\mathbb{E}_{x,y \text{~} p_{data}} \zeta(-y(w^{T}\bar{x} + b)) = \mathbb{E}_{x,y \text{~} p_{data}} \zeta(y(\epsilon||w||_1 -w^{T}x - b))$$</span>**  

<p>$$\bar{x} = x + \eta = x -\epsilon sign(w) $$</p>
<p>$$-y(w^{T}\bar{x} + b) = -y(w^{T}(x -\epsilon sign(w)) + b)$$</p>
<p>$$ = -y(w^{T}x - \epsilon w^{T}sign(w) + b)$$</p>
<p>$$= y(\epsilon||w||_1 -w^{T}x - b)$$</p>
<p>$$\therefore \mathbb{E}_{x,y \text{~} p_{data}} \zeta(-y(w^{T}\bar{x} + b)) = \mathbb{E}_{x,y \text{~} p_{data}} \zeta(y(\epsilon||w||_1 -w^{T}x - b))$$</p>
<br>

ë…¼ë¬¸ì—ì„œëŠ” ìµœì¢…ì ìœ¼ë¡œ êµ¬í•œ ìœ„ì˜ ì‹ì„ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•˜ê³  ìˆë‹¤.  
>This is somewhat similar to L1 regularization.  
However, there are some important differences.  
Most significantly, the L1 penalty is subtracted off the modelâ€™s activation during training, rather than added to the training cost.  
This means that the penalty can eventually start to disappear if the model learns to make confident enough predictions that Î¶ saturates.  This is not guaranteed to happenâ€”in the underfitting regime, adversarial training will simply worsen underfitting.  
We can thus view L1 weight decay as being more â€œworst caseâ€ than adversarial training, because it fails to deactivate in the case of good margin.
>

ê°œì¸ì ìœ¼ë¡œ ì´í•´ê°€ ì˜ ì•ˆë˜ì§€ë§Œ ë‹¤ìŒê³¼ ê°™ì´ í•´ì„í•˜ì˜€ë‹¤.  
ìœ„ì˜ ìµœì¢…ì ì¸ ì‹ì€ <span>$$\mathbb{E}_{x,y \text{~} p_{data}} \zeta(y(\epsilon||w||_1 -w^{T}x - b))$$</span>ì€ L1 Regularizationê³¼ ì‹ì´ ë§¤ìš° ìœ ì‚¬í•˜ê²Œ ë˜ì–´ìˆë‹¤.  
í•˜ì§€ë§Œ L1 Regularizationì˜ ì‹ìœ¼ë¡œì„œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì°¨ì´ë¥¼ ë³´ì´ê³  ìˆë‹¤.    
- L1 Resularization: <span>$$Cost = \frac{1}{n}\sum_{i=1}^{n}{L(y_i,\bar{y(x)})+\frac{\lambda}{2}|w|}$$</span>
- Adversarial Example: <span>$$Cost = \frac{1}{n}\sum_{i=1}^{n}{L(y_i,\bar{y(x+|w|))}}$$</span>

ìœ„ì˜ ì‹ì´ ì •í™•í•˜ì§€ëŠ” ì•Šìœ¼ë‚˜ ì´í•´ë˜ê²Œ ì‰½ê²Œ ì ì—ˆë‹¤.  
ìœ„ì˜ ì‹ì—ì„œ <span>$$\lambda$$</span>ëŠ” ë§¤ìš° ì‘ì€ê°’ìœ¼ë¡œì„œ Trainingê³¼ì •ì—ì„œ L1 Regularizationì˜ ê°’ì€ ì ì  0ì´ë˜ë©´ì„œ Trainingì´ ì§„í–‰ë˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.  
**í•˜ì§€ë§Œ Adversarial Exampleì—ì„œëŠ” LossFunction + <span>$$\lambda$$</span>ê°€ì•„ë‹Œ LossFunctionì˜ Inputì— ì¶”ê°€ì ìœ¼ë¡œ <span>$$\lambda$$</span>ê°€ ë“¤ì–´ê°ìœ¼ë¡œ ì¸í•˜ì—¬ ì¶”ê°€ì ì¸ Biasê°’ì´ ìƒê¸°ê³  ê·¸ë¡œ ì¸í•˜ì—¬ High Bias -> ì¦‰, Underfittingì˜ ìœ„í—˜ì´ ë§¤ìš° í¬ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.**

#### (6) ADVERSARIAL TRAINING OF DEEP NETWORKS
(5) ADVERSARIAL TRAINING OF LINEAR MODELS VERSUS WEIGHT DECAYì—ì„œëŠ” ê°„ë‹¨í•˜ê²Œ **Linearí•œ Modelì¸ ê²½ìš°ì—ì„œ Adversarial Trainingì„ ì–´ë–»ê²Œ ì§„í–‰í•˜ëŠ”ì§€ ì‚´í´ë³´ì•˜ë‹¤.**  
ì´ë²ˆ ChapterëŠ” ì‹¤ì œ DeepLearning Networkì—ì„œ ì–´ë–»ê²Œ Adversarial Trainingì„ ì§„í–‰í•˜ëŠ”ì§€ ì•Œì•„ë³´ì.  
ë…¼ë¬¸ì—ì„œëŠ” DNNì˜ Adversarial Trainingì— ê´€í•´ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ëª…í•˜ê³  ìˆë‹¤.  
DNNì€ ì¼ë°˜ì ì¸ Linearí•œ Modelì— ë¹„í•˜ì—¬ Layerê°€ ë§ê¸° ë•Œë¬¸ì— ë¹„ì„ í˜•ì ì¼ í™•ë¥ ì´ ë†’ìŒìœ¼ë¡œ ì¸í•˜ì—¬ Adversarial Trainingì— ì €í•­í•  í™•ë¥ ì´ ë†’ë‹¤.  
>Szegedy et al. (2014b) showed that by training on a mixture of adversarial and clean examples, a
neural network could be regularized somewhat. Training on adversarial examples is somewhat different from other data augmentation schemes; usually, one augments the data with transformations
such as translations that are expected to actually occur in the test set.

ìœ„ì˜ ì¸ìš©ë¬¸ì„ ì‚´í´ë³´ê²Œ ë˜ë©´ Clean Image + Noiseê°€ ì„ì¸ Imageë¡œ ì¸í•˜ì—¬ ì¢€ë” Regularizationì—ì„œ ê°•ì ì„ ë³´ì¸ë‹¤ê³  í•œë‹¤.  
ì´ëŸ¬í•œ ë°©ì‹ì€ L-BFGSê¸°ë²•ì„ ì‚¬ìš©í•˜ë‚˜ Resourceê°€ ë„ˆë¬´ ë§ì´ ë“¤ê¸° ë•Œë¬¸ì— í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ **FGSMì— ê·¼ê±°í•œ ì •ê·œí™”ì— íš¨ìœ¨ì ì¸ Adversarial Object Function**ì„ ì œê³µí•œë‹¤.  
<p>$$\bar{J}(\theta,x,y) = \alpha J(\theta,x,y)+ (1-\alpha)J(\theta,x+\epsilon sign(\triangledown_x J(\theta,x,y)))$$</p>
<span>$$\alpha$$</span>ê°’ì€ ì‚¬ìš©ìê°€ ì§€ì •í•˜ëŠ” ê°’ì´ë‚˜ í•´ë‹¹ë…¼ë¬¸ì—ì„œëŠ” 0.5ë¡œ ë‘ê³  ì‹¤í—˜í•˜ì˜€ë‹¤ê³  í•œë‹¤.  
ì´ëŸ¬í•œ ê²°ê³¼ëŠ” 89.4%ì˜ Error Rateì—ì„œ 17.9%ì˜ Error Rateë¡œì„œ ì¤„ì–´ë“œëŠ” íš¨ê³¼ë¥¼ ë°œìƒí•˜ê²Œ í•˜ì˜€ë‹¤.  

<br><br>

### Adversarial example using FGSM
Tensorflow 2.0ì—ì„œ ì œê³µí•˜ëŠ” <a href="https://www.tensorflow.org/tutorials/generative/adversarial_fgsm?hl=ko">Adversarial example using FGSM</a>ì„ í†µí•˜ì—¬ ì‹¤ì œ Adversarial Exampleì„ ìƒì„±í•˜ê³  ë…¼ë¬¸ì²˜ëŸ¼ Modelì´ ì˜ëª» Classifyí•˜ëŠ”ì§€ ì‚´í´ë³´ì.  

<br>

#### Import Library

```python
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
import matplotlib as mpl
import matplotlib.pyplot as plt

# matplotlib.rcParamsë¡œ matplotlibì˜ Default Valueë¥¼ ì„¤ì •í•œë‹¤.
mpl.rcParams['figure.figsize'] = (4, 4)
mpl.rcParams['axes.grid'] = False
```
<br>
<br><br>

#### Load Model and Prediction of Clear Image
Imageë¥¼ Classifyí•˜ëŠ” Modelì„ Loadí•œ ë’¤ Pertubationê°€ ì—†ëŠ” Clearí•œ Imageë¥¼ Predictioní•˜ëŠ” ê²°ê³¼ë¥¼ ì‚´í´ë³¸ë‹¤.

```python
# ImageNetìœ¼ë¡œì„œ Pretrainingëœ MobileNetV2 Modelì„ ê°€ì ¸ì˜¨ë‹¤.
pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,
                                                     weights='imagenet')

# Modelì˜ Weightë¥¼ Updateì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤. -> Predictionë§Œ í™•ì¸í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
pretrained_model.trainable = False

# Predictionì˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ Labelì„ ê°€ì ¸ì˜¨ë‹¤.
decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions

# MobileNetV2ì— ë„£ê¸° ìœ„í•œ Dataì˜ ì „ì²˜ë¦¬ ê³¼ì •ì´ë‹¤.
def preprocess(image):
    # Float Typeìœ¼ë¡œì„œ ë³€ê²½
    image = tf.cast(image, tf.float32)
    # Imageë¥¼ 0 ~ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œì„œ ì •ê·œí™”
    image = image/255
    # Imageì˜ Sizeë¥¼ Modelì— ë§ê²Œ 224,224ë¡œì„œ ë³€ê²½
    image = tf.image.resize(image, (224, 224))
    # Batchë¡œì„œ Inputì„ ë°›ìœ¼ë¯€ë¡œ Dimesnion ì¦ê°€
    image = image[None, ...]
    return image

# ImageNetì´ Softmaxë¡œì„œ ì¶œë ¥í•œ ê²°ê³¼ë¥¼ Labelê³¼ Mappingí•˜ëŠ” ì—­í• ì„ í•œë‹¤.
def get_imagenet_label(probs):
    return decode_predictions(probs, top=1)[0][0]

# MobileNetV2ì— ë„£ì„ Imageë¥¼ ê°€ì ¸ì˜¨ë‹¤.
image_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')
image_raw = tf.io.read_file(image_path)
image = tf.image.decode_image(image_raw)

# Data ì „ì²˜ë¦¬ -> Prediction
image = preprocess(image)
image_probs = pretrained_model.predict(image)

# Predictioní•œ ê²°ê³¼ë¥¼ Labelë¡œì„œ Imageë¥¼ Visualizationí•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤.
plt.figure()
plt.axis('off')
# ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ Batchì²˜ë¦¬ë¥¼ í•˜ì˜€ìœ¼ë¯€ë¡œ image[0]ì„ ê°€ì ¸ì™€ì„œ í™•ì¸í•˜ì—¬ì•¼ í•œë‹¤.
plt.imshow(image[0])
# Image Class: MobileNetV2ì—ì„œ ì˜ˆì¸¡í•œ Class
# Class Confidenct: MobileNetV2ì˜ Softmaxì˜ ê°’
_, image_class, class_confidence = get_imagenet_label(image_probs)
plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))
plt.show()
```
<br>
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/Tensorflow/47.png" height="250" width="250" /></div><br>
<br><br>

#### Prediction of Adversarial Example
Adversarial Exampleì„ ìƒì„±í•˜ê³  Modelì—ì„œëŠ” ì–´ë–»ê²Œ Predictioní•˜ëŠ”ì§€ ì‚´í´ë³¸ë‹¤.  
ìœ„ì˜ ë…¼ë¬¸ì—ì„œ ì„¤ëª…í•œ FGSMì˜ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.  
- <span>$$x$$</span>: input
- <span>$$y$$</span>: target
- <span>$$\bar{x}$$</span>: Adversarial example
- <span>$$\theta$$</span>: hyper parameter
- <span>$$J(\theta,x,y)$$</span>: cost function
- <span>$$\epsilon$$</span>: Noiseì˜ í¬ê¸°(ì‚¬ìš©ìê°€ ì§€ì •, ë§¤ìš° ì‘ì€ ê°’)

<p>$$\eta = \epsilon sign(\triangledown_x J(\theta,x,y))$$</p>
<p>$$\bar{x} = x + \eta$$</p>
ì•„ë˜ Codeì—ì„œ ì–´ë–»ê²Œ Mappingí•˜ëŠ”ì§€ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.  

**create_Adversarial_pattern()**  
ìœ„ì˜ Functionì€ <span>$$sign(\triangledown_x J(\theta,x,y))$$</span>ì„ Returní•œë‹¤.  
ìœ„ì—ì„œ ì„¤ëª…í•œ ì‹ê³¼ Mappingí•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.  
- <span>$$x$$</span>: <code>input_image</code>
- <span>$$y$$</span>: <code>input_label</code>
- <span>$$J()$$(loss_object)</span>: <code>tf.keras.losses.CategoricalCrossentropy()</code>
- <span>$$J(\theta,x,y)$$(loss)</span>: <code>loss_object(input_label, prediction)</code>
- <span>$$\triangledown_x J(\theta,x,y)$$(gradient)</span>: <code>tape.gradient(loss, input_image)</code>
- <span>$$sign(\triangledown_x J(\theta,x,y))$$(signed_grad)</span>: <code>tf.sign(gradient)</code>

ìœ„ì˜ Functionìœ¼ë¡œì„œ <span>$$sign(\triangledown_x J(\theta,x,y))$$</span>ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.
```python
# Loss Objectì¸ J()ë¥¼ ì„ ì–¸í•œë‹¤.
loss_object = tf.keras.losses.CategoricalCrossentropy()

# ìµœì¢…ì ìœ¼ë¡œ ğ‘ ğ‘–ğ‘”ğ‘›(â–¿ğ‘¥ğ½(ğœƒ,ğ‘¥,ğ‘¦))ì„ êµ¬í•˜ëŠ” Fucntionì´ë‹¤.
def create_adversarial_pattern(input_image, input_label):
    with tf.GradientTape() as tape:
        # â–¿ğ‘¥ì„ ìœ„í•˜ì—¬ Input Imageì— ëŒ€í•˜ì—¬ ë¯¸ë¶„í•´ì•¼ í•œë‹¤.
        tape.watch(input_image)
        # Modelì˜ Predictionê°’ì„ êµ¬í•œë‹¤. ì‹¤ì œ Loss Objectì˜ ê°’ì„ êµ¬í•˜ê¸° ìœ„í•˜ì—¬
        prediction = pretrained_model(input_image)
        # ğ½(ğœƒ,ğ‘¥,ğ‘¦)ì„ êµ¬í•˜ëŠ” ê³¼ì •ì´ë‹¤.
        loss = loss_object(input_label, prediction)
    
    # â–¿ğ‘¥ğ½(ğœƒ,ğ‘¥,ğ‘¦)ì„ êµ¬í•˜ëŠ” ê³¼ì •ì´ë‹¤.
    gradient = tape.gradient(loss, input_image)
    # ğ‘ ğ‘–ğ‘”ğ‘›(â–¿ğ‘¥ğ½(ğœƒ,ğ‘¥,ğ‘¦))ì„ êµ¬í•˜ëŠ” ê³¼ì •ì´ë‹¤.
    signed_grad = tf.sign(gradient)
    return signed_grad

# MobileNetV2ì˜ ê²°ê³¼ëŠ” Softmaxì˜ ê°’ìœ¼ë¡œì„œ ë‚˜ì˜¤ê²Œ ë˜ë¯€ë¡œ 
# ì‹¤ì œ Loss Objectì— ë„£ê¸° ìœ„í•œ Labelì„ ì„ ì–¸í•˜ì—¬ì•¼ í•œë‹¤.
labrador_retriever_index = 208
label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])

# ğ‘ ğ‘–ğ‘”ğ‘›(â–¿ğ‘¥ğ½(ğœƒ,ğ‘¥,ğ‘¦))ì„ êµ¬í•˜ê³  Visualizationí•˜ëŠ” ê³¼ì •ì´ë‹¤.
perturbations = create_adversarial_pattern(image, label)
plt.imshow(perturbations[0])

# Imageì™€ Model Predictionì˜ ê²°ê³¼ë¥¼ Visualizationí•˜ëŠ” ì—­í• ì´ë‹¤.
def display_images(image, description):
    _, label, confidence = get_imagenet_label(pretrained_model.predict(image))
    plt.figure()
    plt.axis('off')
    plt.imshow(image[0])
    plt.title('{} \n {} : {:.2f}% Confidence'.format(description,
                                                   label, confidence*100))
    plt.show()

# ğœ–ì˜ ê°’ì„ ë‹¤ì–‘í•˜ê²Œ ì¤€ë‹¤. eps = 0 ì´ë©´ Inputìœ¼ë¡œì„œ ê°’ì„ ëŒ€ì…
epsilons = [0, 0.01, 0.1, 0.15]
descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')
                for eps in epsilons]

# ìµœì¢…ì ì¸ Adversarial Exampleì„ ìƒì„±í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤.
for i, eps in enumerate(epsilons):
    # ğ‘¥ = x+ ğœ–ğ‘ ğ‘–ğ‘”ğ‘›(â–¿ğ‘¥ğ½(ğœƒ,ğ‘¥,ğ‘¦)) ë¡œì„œ Adversarial Exampleì„ ìƒì„±í•œë‹¤.
    adv_x = image + eps*perturbations
    adv_x = tf.clip_by_value(adv_x, 0, 1)
    display_images(adv_x, descriptions[i])
```
<br>

<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/Tensorflow/48.png" height="250" width="250" /></div><br>
<div><img src="https://raw.githubusercontent.com/wjddyd66/wjddyd66.github.io/master/static/img/Tensorflow/49.png" height="250" width="250" /></div><br>

<hr>
ì°¸ì¡°: <a href="https://github.com/wjddyd66/Tensorflow2.0/blob/master/FGSM.ipynb">ì›ë³¸ì½”ë“œ</a><br>
ì°¸ì¡°: <a href="https://www.tensorflow.org/tutorials/generative/adversarial_fgsm?hl=ko">Tensorflow2.0 FGSM</a><br>
ì°¸ì¡°: <a href="https://leedakyeong.tistory.com/entry/%EB%85%BC%EB%AC%B8-FGSM-%EB%A6%AC%EB%B7%B0-EXPLAINING-AND-HARNESSING-ADVERSARIAL-EXAMPLES">leedakyeong ë¸”ë¡œê·¸</a><br>
ì°¸ì¡°: <a href="https://lepoeme20.github.io/archive/FGSM">lepeoeme's ë¸”ë¡œê·¸</a><br>
ì½”ë“œì— ë¬¸ì œê°€ ìˆê±°ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ wjddyd66@naver.comìœ¼ë¡œ  Mailì„ ë‚¨ê²¨ì£¼ì„¸ìš”.

